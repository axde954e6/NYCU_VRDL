# VRDL HW3 - Nuclei segmentation
Selected Topics in Visual Recognition using Deep Learning - HW3

## Hardware and Requirements
Google Colab Notebook with GPU

## Reproducing Submission

### Dataset Download
Codalab and download public data: <br>https://codalab.lisn.upsaclay.fr/competitions/333?secret_key=3b31d945-289d-4da6-939d-39435b506ee5#participate-get_data<br>

Training image and mask in the directory "train"
```
TCGA-18-5592-01Z-00-DX1
    |-image
        |-TCGA-18-5592-01Z-00-DX1.png
    |-mask
        |-mask_0001.png...
TCGA-21-5784-01Z-00-DX1...
```
Testing image in the directory "test"
```
TCGA-50-5931-01Z-00-DX1.png
TCGA-A7-A13E-01Z-00-DX1.png ...
```


### Model and data preparation
#### model preparation
In "Mask_RCNN.ipynb"<br>Run 1st kernel to mount drive.<br>Run 2nd and 3rd kernels to git clone Mask RCNN.<br>reference: https://github.com/matterport/Mask_RCNN<br>Put [requirements.txt](https://github.com/axde954e6/NYCU_VRDL/blob/main/HW3/requirements.txt) into Mask_RCNN folder and [nucleus.py](https://github.com/axde954e6/NYCU_VRDL/blob/main/HW3/nucleus.py) into Mask_RCNN/samples/nucleus<br>Run 4th to 7th kernels to prepare relative work.

#### data preparation
The data format can be directly used to Mask RCNN, so just need to upload the dataset to your drive.


### Training
In "Mask_RCNN.ipynb"<br>set the path to training data in 8th and 9th kernels<br>Run 7th and 8th kernels to start your model training.<br>It will save model each epoch, so run 9th kernel to train model with previous result.<br>

If you think it is barely improve, you can reuse model as your pretrain weight and run 8th kernels again.

### Evaluation
I choose 1 image from all training data as validation data.<br>It will automatically calculate loss to each epoch<br><br>

### Generate Result
Set the path to your testing data<br>Run 10th kernel will get a json file with score informance and will generate mask to each testing data in Mask_RCNN/result/mask<br>Run 11th to 14th kernels to git clone cocoapi and make<br>Put [mask_rle.py](https://github.com/axde954e6/NYCU_VRDL/blob/main/HW3/mask_rle.py) to cocoapi/PythonAPI/pycocotools and set the path to mask and json generated by previous in mask_rle.py (line 25 to 28). Then you can get the result.

### Ensemble model
I use two models to get the final result. One for only predict data which image_id equal to 4, other data is detected by another model. Rename the first result to answer_id4.json and put 2 json files and [combine.py](https://github.com/axde954e6/NYCU_VRDL/blob/main/HW3/combine.py) into same path and run below command
```
python combine.py
```

## Pre-trained weight
[HW3 model weight](https://drive.google.com/drive/folders/1IILl5pKeX46MdkrotQ7ISGtZWpdVPCyi?usp=sharing)

## Reference
Mask_RCNN https://github.com/matterport/Mask_RCNN <br>
cocoapi https://github.com/cocodataset/cocoapi


###### tags: `VRDL`
